{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3fee6519",
      "metadata": {
        "id": "3fee6519"
      },
      "source": [
        "# üß† Web Content Summarizer\n",
        "\n",
        "This notebook extracts and summarizes text content from websites using OpenAI-compatible APIs (Groq or Ollama).\n",
        "\n",
        "## Features:\n",
        "- Scrapes content using `requests` or `Selenium`\n",
        "- Uses OpenAI-compatible models like `grok` & Local models like `Ollama` to generate summaries\n",
        "- Supports custom URLs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96c0d65d",
      "metadata": {
        "id": "96c0d65d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "import socket\n",
        "import ipaddress\n",
        "from typing import List\n",
        "from dotenv import load_dotenv\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n",
        "from IPython.display import display, Markdown, update_display\n",
        "from openai import OpenAI\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.common.exceptions import WebDriverException\n",
        "from webdriver_manager.chrome import ChromeDriverManager"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17dbc0f1",
      "metadata": {
        "id": "17dbc0f1"
      },
      "source": [
        "## üîß 1. Load API Keys\n",
        "We load the API key from a `.env` file to securely connect to the Groq or Ollama LLM backend.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c662251",
      "metadata": {
        "id": "6c662251",
        "outputId": "4990a898-b328-49ea-ce07-f96dc986ac2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API key found and looks good so far!\n"
          ]
        }
      ],
      "source": [
        "load_dotenv(override=True)\n",
        "api_key  = os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    print(\"No API_Key found, Please set the API_KEY.\")\n",
        "    exit(1)\n",
        "elif api_key.strip() != api_key:\n",
        "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
        "else:\n",
        "    print(\"API key found and looks good so far!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c10a67b0",
      "metadata": {
        "id": "c10a67b0"
      },
      "outputs": [],
      "source": [
        "openai = OpenAI(api_key=api_key, base_url = \"https://api.groq.com/openai/v1\")\n",
        "ollama_with_openai = OpenAI(api_key = \"ollama\", base_url = \"http://localhost:11434/v1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe8d0bcd",
      "metadata": {
        "id": "fe8d0bcd"
      },
      "source": [
        "## üåê 2. Website Content Extractor\n",
        "This class retrieves the raw HTML and title of a webpage using `requests` or Selenium.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1bb5128",
      "metadata": {
        "id": "d1bb5128"
      },
      "outputs": [],
      "source": [
        "def is_safe_url(url):\n",
        "    try:\n",
        "        parsed = urlparse(url)\n",
        "        if parsed.scheme not in [\"http\", \"https\"] or parsed.netloc == \"\":\n",
        "            return False\n",
        "\n",
        "        host = parsed.hostname\n",
        "        ip = ipaddress.ip_address(socket.gethostbyname(host))\n",
        "        if ip.is_private or ip.is_loopback or ip.is_reserved or ip.is_link_local:\n",
        "            return False\n",
        "    except Exception:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "class Web_Scapper:\n",
        "    \"\"\"\n",
        "    A utility class to represent a Website that we have scraped, using Selenium, with extracted links.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, url):\n",
        "        if not is_safe_url(url):\n",
        "            raise ValueError(\"Invalid or unsafe URL\")\n",
        "\n",
        "        self.url = url\n",
        "        self.title = \"No title found\"\n",
        "        self.text = \"\"\n",
        "        self.links = []\n",
        "\n",
        "        # Setup Selenium\n",
        "        options = Options()\n",
        "        options.add_argument(\"--headless\")\n",
        "        options.add_argument(\"--disable-gpu\")\n",
        "        options.add_argument(\"--no-sandbox\")\n",
        "        options.add_argument(\"--disable-dev-shm-usage\")\n",
        "        options.add_argument(\"--disable-extensions\")\n",
        "        options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
        "\n",
        "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
        "\n",
        "        try:\n",
        "            driver.set_page_load_timeout(20)\n",
        "            driver.get(url)\n",
        "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "            # Get title\n",
        "            self.title = soup.title.string.strip() if soup.title else \"No title found\"\n",
        "\n",
        "            # Remove irrelevant tags\n",
        "            if soup.body:\n",
        "                for tag in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
        "                    tag.decompose()\n",
        "                self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
        "\n",
        "            # Extract all valid links\n",
        "            all_links = [a.get(\"href\") for a in soup.find_all(\"a\") if a.get(\"href\")]\n",
        "            self.links = all_links\n",
        "\n",
        "        except WebDriverException as e:\n",
        "            print(f\"Error loading page with Selenium: {e}\")\n",
        "        finally:\n",
        "            driver.quit()\n",
        "\n",
        "    def get_contents(self):\n",
        "        return f\"Webpage Title:\\n{self.title}\\n\\nWebpage Contents:\\n{self.text}\\n\\n\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48d143f4",
      "metadata": {
        "id": "48d143f4"
      },
      "outputs": [],
      "source": [
        "website = Web_Scapper(\"https://edwarddonner.com\")\n",
        "# print(web_scrapper.get_contents())\n",
        "print(website.get_contents())\n",
        "# web_scrapper.links\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59316142",
      "metadata": {
        "id": "59316142"
      },
      "source": [
        "## üìù 3. Prompt Engineering and Summarization\n",
        "This section defines the prompts used to instruct the `large language model (LLM)` for summarization and provides the core functions to perform the website summarization using the `selected LLM (Groq or Ollama)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64406c06",
      "metadata": {
        "id": "64406c06"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"You are an assistant that analyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.\"\n",
        "\n",
        "def user_prompt_for(website):\n",
        "    user_prompt = f\"- You are looking at a website titled: '{website.title}'.\\n\\n- The contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n{website.text}\"\n",
        "    return user_prompt\n",
        "# print(user_prompt_for(content))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf931267",
      "metadata": {
        "id": "bf931267"
      },
      "outputs": [],
      "source": [
        "# And now: call the OpenAI API. You will get very familiar with this!\n",
        "def summarize(url):\n",
        "    website = Web_Scapper(url)\n",
        "    response = openai.chat.completions.create(\n",
        "        model = \"llama3-70b-8192\",\n",
        "        messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt}\n",
        "        ,{\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
        "    ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "# A function to display this nicely in the Jupyter output, using markdown\n",
        "def display_summary(url):\n",
        "    summary = summarize(url)\n",
        "    display(Markdown(summary))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0dc320b",
      "metadata": {
        "id": "b0dc320b",
        "outputId": "be9740d2-4cfe-447b-b4f8-475e5785fd98"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "**Gopal Info: Your Partner in Digital Growth**\n",
              "=============================================\n",
              "\n",
              "Gopal Info is a digital solutions provider that offers expert services in:\n",
              "\n",
              "* **Graphic Designing**: Crafting eye-catching designs to elevate your brand\n",
              "* **UI/UX Design**: Creating intuitive and engaging user experiences\n",
              "* **Branding Consultation**: Building strong, memorable brands\n",
              "* **Web Designing**: Creating stunning websites that capture your brand's essence\n",
              "* **Web Development**: Building robust and scalable web solutions\n",
              "* **Search Engine Optimization**: Boosting online visibility with proven SEO strategies\n",
              "* **Social Media Marketing**: Driving engagement and growth with targeted social media strategies\n",
              "* **Google Ads**: Maximizing reach and conversions with targeted Google Ads campaigns\n",
              "* **Mobile App Development**: Developing innovative mobile apps that enhance user experience\n",
              "\n",
              "The company follows an agile methodology, prioritizing collaboration, creativity, and quality at every step of the project. With a diverse range of advanced technologies, Gopal Info aims to empower businesses with innovative digital solutions to drive growth and success."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display_summary(\"https://www.gopalinfo.com/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d7a6475",
      "metadata": {
        "id": "0d7a6475",
        "outputId": "a0bfa89f-e503-4648-9e13-3a4ad06473d9"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# TechCrunch: Startup and Technology News\n",
              "=============================\n",
              "\n",
              "**Latest News**\n",
              "---------------\n",
              "\n",
              "* European VC breaks taboo by investing in pure defense tech from Ukraine‚Äôs war zones\n",
              "* LangChain is about to become a unicorn, sources say\n",
              "* GenAI as a shopping assistant set to explode during Prime Day sales\n",
              "* Apple COO Jeff Williams to step down later this month\n",
              "* SpaceX in talks to raise new funding at $400B valuation\n",
              "\n",
              "**Top Headlines**\n",
              "----------------\n",
              "\n",
              "* Grok is being antisemitic again and also the sky is blue\n",
              "* Hugging Face opens up orders for its Reachy Mini desktop robots\n",
              "* Rivian spinoff Also raises another $200M to build e-bikes and more\n",
              "* In a blow to Google Cloud, Replit partners with Microsoft\n",
              "* European VC breaks taboo by investing in pure defense tech from Ukraine‚Äôs war zones\n",
              "\n",
              "**In Brief**\n",
              "-------------\n",
              "\n",
              "* Rivian spinoff Also raises another $200M to build e-bikes and more\n",
              "* US government confirms arrest of Chinese national accused of stealing COVID research and mass-hacking email servers\n",
              "* SpaceX in talks to raise new funding at $400B valuation\n",
              "* Mistral is reportedly in talks to raise $1B\n",
              "* ByteDance reportedly plans to release US-specific version of CapCut\n",
              "\n",
              "**Upcoming Events**\n",
              "------------------\n",
              "\n",
              "* TechCrunch All Stage 2025 (July 15, 2025)\n",
              "* TechCrunch Disrupt 2025 (October 27-29, 2025)\n",
              "* StrictlyVC Palo Alto (December 3, 2025)"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display_summary(\"https://techcrunch.com\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}