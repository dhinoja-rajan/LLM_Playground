{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3fee6519",
      "metadata": {
        "id": "3fee6519"
      },
      "source": [
        "# üß† Web Content Summarizer\n",
        "\n",
        "This notebook extracts and summarizes text content from websites using OpenAI-compatible APIs (Groq or Ollama).\n",
        "\n",
        "## Features:\n",
        "- Scrapes content using `requests` or `Selenium`\n",
        "- Uses OpenAI-compatible models like `grok` & Local models like `Ollama` to generate summaries\n",
        "- Supports custom URLs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "21d1066a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install requests python-dotenv beautifulsoup4 ipython openai selenium webdriver-manager\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "96c0d65d",
      "metadata": {
        "id": "96c0d65d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "import socket\n",
        "import ipaddress\n",
        "from typing import List\n",
        "from dotenv import load_dotenv\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n",
        "from IPython.display import display, Markdown, update_display\n",
        "from openai import OpenAI\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.common.exceptions import WebDriverException\n",
        "from webdriver_manager.chrome import ChromeDriverManager"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17dbc0f1",
      "metadata": {
        "id": "17dbc0f1"
      },
      "source": [
        "## üîß 1. Load API Keys\n",
        "We load the API key from a `.env` file to securely connect to the Groq or Ollama LLM backend.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6c662251",
      "metadata": {
        "id": "6c662251",
        "outputId": "4990a898-b328-49ea-ce07-f96dc986ac2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API key found and looks good so far!\n"
          ]
        }
      ],
      "source": [
        "load_dotenv(override=True)\n",
        "api_key  = os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    print(\"No API_Key found, Please set the API_KEY.\")\n",
        "    exit(1)\n",
        "elif api_key.strip() != api_key:\n",
        "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
        "else:\n",
        "    print(\"API key found and looks good so far!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c10a67b0",
      "metadata": {
        "id": "c10a67b0"
      },
      "outputs": [],
      "source": [
        "openai = OpenAI(api_key=api_key, base_url = \"https://api.groq.com/openai/v1\")\n",
        "ollama_with_openai = OpenAI(api_key = \"ollama\", base_url = \"http://localhost:11434/v1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe8d0bcd",
      "metadata": {
        "id": "fe8d0bcd"
      },
      "source": [
        "## üåê 2. Website Content Extractor\n",
        "This class retrieves the raw HTML and title of a webpage using `requests` or Selenium.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d1bb5128",
      "metadata": {
        "id": "d1bb5128"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Explanation of this code: https://chatgpt.com/share/686f8aed-a210-8007-970d-37906975fa4f\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def is_safe_url(url):\n",
        "    try:\n",
        "        parsed = urlparse(url)\n",
        "        if parsed.scheme not in [\"http\", \"https\"] or parsed.netloc == \"\":\n",
        "            return False\n",
        "\n",
        "        host = parsed.hostname\n",
        "        ip = ipaddress.ip_address(socket.gethostbyname(host))\n",
        "        if ip.is_private or ip.is_loopback or ip.is_reserved or ip.is_link_local:\n",
        "            return False\n",
        "    except Exception:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "class Web_Scapper:\n",
        "    \"\"\"\n",
        "    A utility class to represent a Website that we have scraped, using Selenium, with extracted links.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, url):\n",
        "        if not is_safe_url(url):\n",
        "            raise ValueError(\"Invalid or unsafe URL\")\n",
        "\n",
        "        self.url = url\n",
        "        self.title = \"No title found\"\n",
        "        self.text = \"\"\n",
        "        self.links = []\n",
        "\n",
        "        # Setup Selenium\n",
        "        options = Options()\n",
        "        options.add_argument(\"--headless\")\n",
        "        options.add_argument(\"--disable-gpu\")\n",
        "        options.add_argument(\"--no-sandbox\")\n",
        "        options.add_argument(\"--disable-dev-shm-usage\")\n",
        "        options.add_argument(\"--disable-extensions\")\n",
        "        options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
        "\n",
        "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
        "\n",
        "        try:\n",
        "            driver.set_page_load_timeout(60)\n",
        "            driver.get(url)\n",
        "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "            # Get title\n",
        "            self.title = soup.title.string.strip() if soup.title else \"No title found\"\n",
        "\n",
        "            # Remove irrelevant tags\n",
        "            if soup.body:\n",
        "                for tag in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
        "                    tag.decompose()\n",
        "                self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
        "\n",
        "            # Extract all valid links\n",
        "            all_links = [a.get(\"href\") for a in soup.find_all(\"a\") if a.get(\"href\")]\n",
        "            self.links = all_links\n",
        "\n",
        "        except WebDriverException as e:\n",
        "            print(f\"Error loading page with Selenium: {e}\")\n",
        "        finally:\n",
        "            driver.quit()\n",
        "\n",
        "    def get_contents(self):\n",
        "        return f\"Webpage Title:\\n{self.title}\\n\\nWebpage Contents:\\n{self.text}\\n\\n\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "48d143f4",
      "metadata": {
        "id": "48d143f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Webpage Title:\n",
            "Home - Edward Donner\n",
            "\n",
            "Webpage Contents:\n",
            "Skip to content\n",
            "Home\n",
            "Connect Four\n",
            "Outsmart\n",
            "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
            "About\n",
            "Posts\n",
            "Well, hi there.\n",
            "I‚Äôm Ed. I like writing code and experimenting with LLMs, and hopefully you‚Äôre here because you do too. I also enjoy DJing (but I‚Äôm badly out of practice), amateur electronic music production (\n",
            "very\n",
            "amateur) and losing myself in\n",
            "Hacker News\n",
            ", nodding my head sagely to things I only half understand.\n",
            "I‚Äôm the co-founder and CTO of\n",
            "Nebula.io\n",
            ". We‚Äôre applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I‚Äôm previously the founder and CEO of AI startup untapt,\n",
            "acquired in 2021\n",
            ".\n",
            "We work with groundbreaking, proprietary LLMs verticalized for talent, we‚Äôve\n",
            "patented\n",
            "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
            "Connect\n",
            "with me for more!\n",
            "May 28, 2025\n",
            "Connecting my courses ‚Äì become an LLM expert and leader\n",
            "May 18, 2025\n",
            "2025 AI Executive Briefing\n",
            "April 21, 2025\n",
            "The Complete Agentic AI Engineering Course\n",
            "January 23, 2025\n",
            "LLM Workshop ‚Äì Hands-on with Agents ‚Äì resources\n",
            "Navigation\n",
            "Home\n",
            "Connect Four\n",
            "Outsmart\n",
            "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
            "About\n",
            "Posts\n",
            "Get in touch\n",
            "ed [at] edwarddonner [dot] com\n",
            "www.edwarddonner.com\n",
            "Follow me\n",
            "LinkedIn\n",
            "Twitter\n",
            "Facebook\n",
            "Subscribe to newsletter\n",
            "Type your email‚Ä¶\n",
            "Subscribe\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# website = Web_Scapper(\"https://edwarddonner.com\")\n",
        "# # print(web_scrapper.get_contents())\n",
        "# print(website.get_contents())\n",
        "# # web_scrapper.links\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59316142",
      "metadata": {
        "id": "59316142"
      },
      "source": [
        "## üìù 3. Prompt Engineering and Summarization\n",
        "This section defines the prompts used to instruct the `large language model (LLM)` for summarization and provides the core functions to perform the website summarization using the `selected LLM (Groq or Ollama)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "64406c06",
      "metadata": {
        "id": "64406c06"
      },
      "outputs": [],
      "source": [
        "system_prompt = (\n",
        "    \"You are a highly intelligent assistant tasked with analyzing website content. \"\n",
        "    \"Your job is to extract and summarize the **core purpose** and **main content** of the site, ignoring any navigation bars, footers, cookie banners, or repetitive UI elements. \"\n",
        "    \"You excel at identifying meaningful information such as services offered, articles, announcements, product details, or business descriptions. \"\n",
        "    \"Always format your response in **markdown**, and present the summary in a clean, human-readable format that would make sense to someone who has never seen the site before.\"\n",
        ")\n",
        "\n",
        "\n",
        "def user_prompt_for(website):\n",
        "    user_prompt = (\n",
        "        f\"## Website Title\\n\"\n",
        "        f\"**{website.title}**\\n\\n\"\n",
        "        f\"## Instructions\\n\"\n",
        "        f\"You are analyzing the contents of this website. Please provide a clear and concise markdown summary of the website‚Äôs purpose and content. \"\n",
        "        f\"Include any relevant details such as:\\n\"\n",
        "        f\"- Services, products, or features offered\\n\"\n",
        "        f\"- Blog posts, articles, or resources\\n\"\n",
        "        f\"- News or announcements\\n\"\n",
        "        f\"- Contact information, locations, or teams (if present)\\n\\n\"\n",
        "        f\"### Important:\\n\"\n",
        "        f\"- **Ignore** navigation links, UI controls, cookie notices, or footer text.\\n\"\n",
        "        f\"- Focus on meaningful, unique content visible to a visitor.\\n\\n\"\n",
        "        f\"## Website Content\\n\"\n",
        "        f\"{website.text}\"\n",
        "    )\n",
        "    return user_prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bf931267",
      "metadata": {
        "id": "bf931267"
      },
      "outputs": [],
      "source": [
        "# And now: call the OpenAI API. You will get very familiar with this!\n",
        "def summarize(url):\n",
        "    website = Web_Scapper(url)\n",
        "    response = openai.chat.completions.create(\n",
        "        model = \"llama3-70b-8192\",\n",
        "        messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt}\n",
        "        ,{\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
        "    ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "# A function to display this nicely in the Jupyter output, using markdown\n",
        "def display_summary(url):\n",
        "    summary = summarize(url)\n",
        "    display(Markdown(summary))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "af62785a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "**Microweb Software Pvt Ltd: Full Stack Development Company**\n",
              "===============================================\n",
              "\n",
              "**Core Purpose:**\n",
              "Microweb Software Pvt Ltd is a full-stack development company that specializes in translating digital challenges into seamless strategies, focusing on delivering exceptional end-user experiences. They combine design, technology, and data to create engaging digital platforms.\n",
              "\n",
              "**Main Content:**\n",
              "\n",
              "### Services\n",
              "\n",
              "* Cloud Application Development Services\n",
              "* Azure DevOps Services\n",
              "* Golang Development Services\n",
              "* DevOps Consulting Services\n",
              "* Business Transformation\n",
              "* Laravel Application Development\n",
              "* Symfony Web Development\n",
              "* Node.js Development\n",
              "* AngularJs Web Development Services\n",
              "* Ruby on Rails Application Development\n",
              "* Microsoft Development\n",
              "* Mobile Application Development\n",
              "* IoT and Embedded Systems & Smart Solutions\n",
              "* Cloud Technology\n",
              "* ReactJS Development\n",
              "* Drupal Web Development Services\n",
              "* 2D and 3D Video Animation\n",
              "* UI & UX Design\n",
              "* Web Development\n",
              "* Enterprise Solutions\n",
              "* Digital Marketing\n",
              "* Software Outsource to India\n",
              "* Graphic Designing\n",
              "* eCommerce Development\n",
              "* WordPress Web Development\n",
              "* WooCommerce Development\n",
              "* Shopify Development\n",
              "* Python Development\n",
              "* AI & ML Services\n",
              "\n",
              "### Case Studies\n",
              "\n",
              "* Crefin ‚Äì Process Automation for Loan Processing in the USA\n",
              "* SkyEduco ‚Äì AI-Powered Study Abroad Portal with AI Features\n",
              "* Idiagnose ‚Äì AI-Powered Chatbot to Train Doctors\n",
              "\n",
              "### Contact Information\n",
              "\n",
              "* Location: 502, Matrix Building, Corporate Road, Prahladnagar, Behind Divya Bhaskar, Makarba, Ahmedabad-380015, India\n",
              "* Phone: +91 94264 83914\n",
              "* Email: [available on the website]\n",
              "\n",
              "Note: The website does not have any blog posts, articles, or resources apart from the case studies."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display_summary(\"https://www.microwebtec.com/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b0dc320b",
      "metadata": {
        "id": "b0dc320b",
        "outputId": "be9740d2-4cfe-447b-b4f8-475e5785fd98"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "**Gopal Info Website Summary**\n",
              "=============================\n",
              "\n",
              "**Core Purpose**\n",
              "Gopal Info is a digital agency providing expert solutions in graphic design, website development, digital marketing, SEO, and social media management to help businesses thrive online.\n",
              "\n",
              "**Main Content**\n",
              "### Services\n",
              "\n",
              "* Graphic Designing: Crafting eye-catching designs to elevate brands\n",
              "* UI/UX Design: Creating intuitive and engaging user experiences\n",
              "* Branding Consulting: Building strong, memorable brands with expert guidance\n",
              "* Social Media Marketing: Driving engagement and growth with targeted strategies\n",
              "* Search Engine Optimization: Boosting online visibility with proven SEO strategies\n",
              "* Google Ads: Maximizing reach and conversions with targeted campaigns\n",
              "* Web Designing: Creating stunning websites that capture brand essence\n",
              "* Website Development: Building robust and scalable web solutions\n",
              "* Mobile App Development: Developing innovative mobile apps that enhance user experience\n",
              "\n",
              "### Technologies\n",
              "Gopal Info utilizes a range of advanced technologies to deliver high-quality services.\n",
              "\n",
              "### How we work\n",
              "The agency follows an agile methodology prioritizing collaboration, creativity, and quality at every step, from initial consultation to final delivery.\n",
              "\n",
              "### Testimonials\n",
              "Empowering businesses with innovative digital solutions to drive growth and success.\n",
              "\n",
              "### Contact Information\n",
              "Address: 502 - Matrix, Makarba, Ahmedabad - 380015, India\n",
              "Get in touch through the website's contact form or WhatsApp."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display_summary(\"https://www.gopalinfo.com/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0d7a6475",
      "metadata": {
        "id": "0d7a6475",
        "outputId": "a0bfa89f-e503-4648-9e13-3a4ad06473d9"
      },
      "outputs": [],
      "source": [
        "# display_summary(\"https://techcrunch.com\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
